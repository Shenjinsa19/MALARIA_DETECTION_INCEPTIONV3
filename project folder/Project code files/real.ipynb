{"cells":[{"cell_type":"markdown","source":["#1.IMPORT THE TENSOR FLOW"],"metadata":{"id":"hSYXOBJu8VAa"}},{"cell_type":"code","source":["pip install tensorflow"],"metadata":{"id":"dJFpGkmrxOO7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748149849569,"user_tz":-330,"elapsed":1489,"user":{"displayName":"projects","userId":"02182998604747504761"}},"outputId":"7674f037-0f8a-4335-b6da-4dbbadb988f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"markdown","source":["#2.Import nessary libraries\n"],"metadata":{"id":"kZksFB2I85h2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1p2UvfrqI2ZA"},"outputs":[],"source":["#import nessary libraries\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n"]},{"cell_type":"markdown","source":["# 2.Dataset downloading"],"metadata":{"id":"7vKTsJey9nud"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12951,"status":"ok","timestamp":1748149918631,"user":{"displayName":"projects","userId":"02182998604747504761"},"user_tz":-330},"id":"Yxvq88qyJDlW","outputId":"374660e6-67cc-4bc2-8a43-55c5921c6535"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading dataset...\n","Download successful, extracting files...\n","Extraction completed.\n","Amount of parasitized images: 13779\n","Amount of uninfected images: 13779\n","Total Images: 27558\n"]}],"source":["#dataset downloading\n","import os\n","import glob\n","import requests\n","import zipfile\n","import io\n","\n","# Step 1: Download the dataset ZIP from GitHub\n","url = \"https://github.com/xmartlabs/malaria-detector/archive/refs/heads/master.zip\"\n","print(\"Downloading dataset...\")\n","response = requests.get(url)\n","if response.status_code == 200:\n","    print(\"Download successful, extracting files...\")\n","    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n","        zip_ref.extractall(\".\")\n","    print(\"Extraction completed.\")\n","else:\n","    print(\"Failed to download dataset.\")\n","    exit(1)\n","\n","# Step 2: Define dataset directories after extraction\n","ROOT_DATA_DIR = './malaria-detector-master/cell_images'\n","INFECTED_DIR = os.path.join(ROOT_DATA_DIR, 'Parasitized')\n","UNINFECTED_DIR = os.path.join(ROOT_DATA_DIR, 'Uninfected')\n","\n","# Step 3: Get list of image files\n","infected_files = glob.glob(os.path.join(INFECTED_DIR, '*.png'))\n","uninfected_files = glob.glob(os.path.join(UNINFECTED_DIR, '*.png'))\n","\n","# Step 4: Print the counts\n","print(f'Amount of parasitized images: {len(infected_files)}')\n","print(f'Amount of uninfected images: {len(uninfected_files)}')\n","print(f'Total Images: {len(infected_files) + len(uninfected_files)}')\n"]},{"cell_type":"markdown","source":["#3.To mount the google drive for dataset"],"metadata":{"id":"M3elNkvR-E7p"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUfbod1YIZVp","outputId":"6aeb1f57-cdcf-4f45-9874-cccb4d26aeb3","executionInfo":{"status":"ok","timestamp":1748150096456,"user_tz":-330,"elapsed":177824,"user":{"displayName":"projects","userId":"02182998604747504761"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","^C\n"]}],"source":["#to mount the google drive for dataset\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Then copy dataset folder to Drive, e.g.:\n","!cp -r ./malaria-detector-master /content/drive/MyDrive/\n"]},{"cell_type":"markdown","source":["#4.Building the model"],"metadata":{"id":"sCMokwdk-K8v"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":2052,"status":"ok","timestamp":1748150098512,"user":{"displayName":"projects","userId":"02182998604747504761"},"user_tz":-330},"id":"rkC6pXjmId-o","outputId":"b3097a8a-ddbd-4a7b-f038-1dd13a54d640"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m8,389,632\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,025\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,389,632</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,193,441\u001b[0m (115.18 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,193,441</span> (115.18 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,159,009\u001b[0m (115.05 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,159,009</span> (115.05 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,432\u001b[0m (134.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,432</span> (134.50 KB)\n","</pre>\n"]},"metadata":{}}],"source":["from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","# Load InceptionV3 base model (without top layers)\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n","\n","# Make base model trainable\n","base_model.trainable = True\n","\n","# Build the full model\n","model = Sequential([\n","    base_model,\n","    Flatten(),                       # Output: (None, 8192)\n","    Dense(1024, activation='relu'),  # Output: (None, 1024)\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')   # Binary classification\n","])\n","\n","# Compile the model\n","model.compile(\n","    optimizer=Adam(learning_rate=1e-4),\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Print model summary\n","model.summary()\n"]},{"cell_type":"markdown","source":["#5. Data preparation and augmentation"],"metadata":{"id":"l3zvRwMs_EOy"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":583,"status":"ok","timestamp":1748150099113,"user":{"displayName":"projects","userId":"02182998604747504761"},"user_tz":-330},"id":"KZ7xwlfeI8Im","outputId":"671354c0-9269-4aa6-eefb-786824f4d55e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 22048 images belonging to 2 classes.\n","Found 5510 images belonging to 2 classes.\n"]}],"source":["# Data preparation and augmentation\n","# Data Augmentation & Normalization Setup\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","#Training Data Preparation\n","train_generator = train_datagen.flow_from_directory(\n","    './malaria-detector-master/cell_images',\n","    target_size=(128, 128),  # match model input\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","#Validation Data Preparation\n","val_generator = train_datagen.flow_from_directory(\n","    './malaria-detector-master/cell_images',\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='validation'\n",")\n"]},{"cell_type":"markdown","source":["#6.Fitting the model"],"metadata":{"id":"BXeuh4FB_Np2"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6172nIsnI86b","outputId":"e3736a85-a2d0-4eb6-9baa-471c72f9128f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m656/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:57\u001b[0m 5s/step - accuracy: 0.8884 - loss: 0.2736"]}],"source":["history = model.fit(\n","    train_generator,\n","    validation_data=val_generator,\n","    epochs=5,\n","    verbose=1\n",")\n"]},{"cell_type":"markdown","source":["# 7.Plot accuracy"],"metadata":{"id":"fplKNZmv_mly"}},{"cell_type":"code","source":["# Plot accuracy\n","plt.figure(figsize=(8, 5))\n","plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot loss\n","plt.figure(figsize=(8, 5))\n","plt.plot(history.history['loss'], label='Train Loss', marker='o')\n","plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"N2jTui-c-NM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#8.Single image and multiple image processing"],"metadata":{"id":"4M4fZ897_sSD"}},{"cell_type":"code","source":["#single image and multiple image processing\n","import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","\n","# Load your trained model\n","model = load_model('/content/drive/MyDrive/InceptionV3.h5')\n","\n","def preprocess_and_predict(img_path):\n","    try:\n","        img = image.load_img(img_path, target_size=(128, 128))\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)\n","        img_array = img_array / 255.0\n","        prediction = model.predict(img_array)[0][0]\n","        label = 'Infected' if prediction >= 0.5 else 'Uninfected'\n","        return float(prediction), label\n","    except Exception as e:\n","        print(f\" Error processing {img_path}: {e}\")\n","        return None, None\n","\n","choice = input(\"Choose prediction type (enter number):\\n1. Single Image\\n2. Folder of Images\\nYour choice: \")\n","\n","if choice == '1':\n","    img_path = input(\"Enter the full path of the image: \").strip()\n","    if not os.path.isfile(img_path):\n","        print(\"File does not exist:\", img_path)\n","    else:\n","        pred_score, pred_label = preprocess_and_predict(img_path)\n","        if pred_score is not None:\n","            print(f\"Prediction score: {pred_score}\")\n","            print(f\"Result: {pred_label}\")\n","\n","elif choice == '2':\n","    folder_path = input(\"Enter the full path of the image folder: \").strip()\n","    if not os.path.isdir(folder_path):\n","        print(\" Folder does not exist:\", folder_path)\n","    else:\n","        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","        if not image_files:\n","            print(\" No images found in folder:\", folder_path)\n","        else:\n","            print(f\" Found {len(image_files)} images.\")\n","            results = []\n","            for filename in image_files:\n","                img_path = os.path.join(folder_path, filename)\n","                pred_score, pred_label = preprocess_and_predict(img_path)\n","                if pred_score is not None:\n","                    results.append({\n","                        'filename': filename,\n","                        'prediction_score': pred_score,\n","                        'label': pred_label\n","                    })\n","            if results:\n","                df = pd.DataFrame(results)\n","                output_csv = '/content/drive/MyDrive/cell_predictions.csv'\n","                df.to_csv(output_csv, index=False)\n","                print(f\" Predictions saved to: {output_csv}\")\n","            else:\n","                print(\" No predictions made. Check for errors above.\")\n","else:\n","    print(\" Invalid choice. Please run again and choose 1 or 2.\")\n"],"metadata":{"id":"ZKGOUI2h3ukz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#9.Save the model"],"metadata":{"id":"wjeDmHMg_5Hc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gj-eHGsNKP9f"},"outputs":[],"source":["model.save('/content/drive/MyDrive/malaria_inceptionv3_model.h5')\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyN/MqzlnhdBF9UYiRDk0FEl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}